{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd113fc-a5bf-4eaa-920c-d8ad048f4919",
   "metadata": {},
   "source": [
    "# Patent Applicants and Technology Distribution in Germany by Landkreis\n",
    "\n",
    "This notebook analyzes patent applicants and technology distributions across Germany's NUTS Level 3 regions (Landkreise). \n",
    "\n",
    "Using SQL queries with the PATSTAT database, the notebook demonstrates how to:\n",
    "1. Extract patent data at federal state and district levels.\n",
    "2. Map NUTS codes to region names.\n",
    "3. Add CPC subclass titles for better insights.\n",
    "4. Visualize the results interactively with **Pygwalker**.\n",
    "\n",
    "The ultimate goal is to refactor the process into a clean, modular Python class to present it at the Patent Knowledge Forum 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9604eff5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 1: Setup and Import Libraries\n",
    "\n",
    "This step imports all the necessary libraries for:\n",
    "- Querying the PATSTAT database.\n",
    "- Handling data with Pandas.\n",
    "- Visualizing data using Pygwalker.\n",
    "- Parsing XML to extract CPC subclass titles.\n",
    "\n",
    "### Key Libraries\n",
    "- **Pandas**: For data manipulation.\n",
    "- **SQLAlchemy**: To handle database queries.\n",
    "- **Pygwalker**: For interactive visualization.\n",
    "- **lxml**: For XML parsing (to extract CPC subclass titles).\n",
    "- **Geopandas**: Optional for geographical mapping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7cd478-de4d-42fc-9f7b-33f082092ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas libraries for data frame handling\n",
    "# Import time library for measuring sql execution time\n",
    "import time\n",
    "\n",
    "# Import Geopandas for mapping if needed later\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Import pygwalker library for vizualisation\n",
    "import pygwalker as pyg\n",
    "\n",
    "# Import the EPO library module for PATSTAT\n",
    "from epo.tipdata.patstat import PatstatClient\n",
    "\n",
    "# Import xml lib for IPC sub group labels\n",
    "from lxml import etree as ET\n",
    "\n",
    "# Import sql library for easy sql execution\n",
    "from sqlalchemy import create_engine, func\n",
    "from sqlalchemy.sql import literal_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b98969b-551a-41bc-9d52-68a92066e49d",
   "metadata": {},
   "source": [
    "The PATSTAT client is instantiated to connect to the test or production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d772e8d-15d1-4a3e-bd39-7b960556dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intantiate the client objects with reduced data set with TEST or the full dataset with PRDOD\n",
    "#patstat = PatstatClient(env=\"TEST\")\n",
    "patstat = PatstatClient(env='PROD')\n",
    "\n",
    "# Instantiate the ORM\n",
    "db = patstat.orm()\n",
    "\n",
    "# import all the tables we need\n",
    "from epo.tipdata.patstat.database.models import (\n",
    "    TLS201_APPLN,\n",
    "    TLS202_APPLN_TITLE,\n",
    "    TLS206_PERSON,\n",
    "    TLS207_PERS_APPLN,\n",
    "    TLS224_APPLN_CPC,\n",
    "    TLS231_INPADOC_LEGAL_EVENT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e23ba1-4424-4aea-8564-2c58be15e359",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 2: Develop Initial SQL Queries\n",
    "\n",
    "### Test Query 1: Granted Applications Filed at EPO in 2010\n",
    "This query retrieves a list of granted applications filed at the European Patent Office (EPO) in the year 2010. \n",
    "\n",
    "It showcases:\n",
    "- Filtering by filing year.\n",
    "- Filtering by application authority (`EP` for European Patent).\n",
    "- Retrieving only granted applications.\n",
    "\n",
    "The goal is to ensure the PATSTAT connection and ORM setup are working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc05ff6c-ba74-4957-be1a-fc122746a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query 1\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "q = db.query(\n",
    "    TLS201_APPLN.appln_id,\n",
    "    TLS201_APPLN.appln_auth,\n",
    "    TLS201_APPLN.appln_nr,\n",
    "    TLS201_APPLN.appln_kind,\n",
    "    TLS201_APPLN.appln_filing_date,\n",
    ").filter(\n",
    "    TLS201_APPLN.appln_filing_year == 2010,\n",
    "    TLS201_APPLN.appln_auth == \"EP\",\n",
    "    TLS201_APPLN.granted == \"Y\",\n",
    ")\n",
    "\n",
    "df = patstat.df(q)\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the execution time\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Query execution time: {execution_time:.2f} seconds\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2373ef70-d61b-4657-9f2a-c8a760d7d032",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Test Query 2: Hitlist of Chinese Applicants at EPO\n",
    "\n",
    "This query creates a hitlist of Chinese applicants who filed patents at the EPO. It demonstrates:\n",
    "- Joining tables to link applicants with their filings.\n",
    "- Filtering for Chinese applicants (`person_ctry_code = 'CN'`).\n",
    "- Grouping by applicant name to count their applications.\n",
    "- Ordering by the number of applications filed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e413467-a47b-4556-bba4-f02061beacf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query 2\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "q = (\n",
    "    db.query(\n",
    "        TLS206_PERSON.psn_name,\n",
    "        TLS206_PERSON.person_ctry_code,\n",
    "        func.count(TLS201_APPLN.appln_id).label(\"APPLICATIONS_AT_EPO\"),\n",
    "    )\n",
    "    .select_from(TLS206_PERSON)\n",
    "    .join(TLS207_PERS_APPLN)\n",
    "    .join(TLS201_APPLN)\n",
    "    .filter(\n",
    "        TLS206_PERSON.person_ctry_code == \"CN\",\n",
    "        TLS207_PERS_APPLN.applt_seq_nr > 0,\n",
    "        TLS207_PERS_APPLN.invt_seq_nr == 0,\n",
    "        TLS201_APPLN.appln_auth == \"EP\",\n",
    "    )\n",
    "    .group_by(TLS206_PERSON.psn_name, TLS206_PERSON.person_ctry_code)\n",
    "    .order_by(func.count(TLS201_APPLN.appln_id).desc())\n",
    "    .limit(100)\n",
    ")\n",
    "df = patstat.df(q)\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the execution time\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Query execution time: {execution_time:.2f} seconds\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac41d28-a05a-4329-a2f9-2628af7d0906",
   "metadata": {},
   "source": [
    "## Step 3: Co-Develop a Query with Gen AI Chatbot\n",
    "\n",
    "Using PATSTAT, this step introduces a SQL query to analyze patent applicants and technologies at the district level in Germany (NUTS Level 3). \n",
    "\n",
    "### Key Highlights:\n",
    "1. Group by NUTS Level 3 (`Landkreis`) to map applicant activity across districts.\n",
    "2. Add **technology fields** by including CPC subclass codes.\n",
    "3. Visualize the results using Pygwalker for interactive exploration.\n",
    "\n",
    "The query is refined step-by-step to include:\n",
    "- Applicant names and NUTS codes.\n",
    "- Application counts grouped by technology fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5389509e-fe2a-46dc-99a2-8c63c3e19076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query patent applicants and technology distribution with filing year and grant status\n",
    "## extract the NUTS Level 1 = Federal State\n",
    "## extract the CPC sub classes (CPC hierachy level 3: e.g. B66B = )\n",
    "\n",
    "#### Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "q = (\n",
    "    db.query(\n",
    "        TLS206_PERSON.person_name.label(\"applicant\"),\n",
    "        TLS206_PERSON.nuts.label(\"nuts_code\"),\n",
    "        literal_column(\"SUBSTR(nuts, 1, 3)\").label(\n",
    "            \"federal_state_code\"\n",
    "        ),  # Federal state (NUTS Level 1)\n",
    "        TLS224_APPLN_CPC.cpc_class_symbol.label(\"technology_field\"),  # Technology field\n",
    "        literal_column(\"SUBSTR(cpc_class_symbol, 1, 4)\").label(\"cpc_subclass\"),\n",
    "        TLS201_APPLN.appln_filing_year.label(\"filing_year\"),  # Filing year\n",
    "        TLS201_APPLN.granted.label(\"granted\"),  # Grant status\n",
    "        func.count(TLS201_APPLN.appln_id).label(\"appln_count\"),  # Application count\n",
    "    )\n",
    "    .select_from(TLS206_PERSON)\n",
    "    .join(TLS207_PERS_APPLN, TLS206_PERSON.person_id == TLS207_PERS_APPLN.person_id)\n",
    "    .join(TLS201_APPLN, TLS207_PERS_APPLN.appln_id == TLS201_APPLN.appln_id)\n",
    "    .join(TLS224_APPLN_CPC, TLS201_APPLN.appln_id == TLS224_APPLN_CPC.appln_id)\n",
    "    .filter(\n",
    "        TLS206_PERSON.nuts.startswith(\"DE\"),  # Filter for Germany NUTS code\n",
    "        TLS206_PERSON.nuts_level == 3,  # Limit to NUTS level 3\n",
    "    )\n",
    "    .group_by(\n",
    "        TLS201_APPLN.appln_filing_year,  # Group by filing year\n",
    "        TLS206_PERSON.nuts,  # Group by NUTS Level 3 code\n",
    "        literal_column(\"SUBSTR(nuts, 1, 3)\"),  # Group by federal state code\n",
    "        TLS224_APPLN_CPC.cpc_class_symbol,  # Group by technology field\n",
    "        TLS206_PERSON.person_name,  # Group by person name\n",
    "        TLS201_APPLN.granted,  # Group by grant status\n",
    "    )\n",
    "    .order_by(TLS206_PERSON.nuts)\n",
    ")  # , TLS201_APPLN.appln_filing_year)\n",
    "\n",
    "# Execute the query\n",
    "df = patstat.df(q)\n",
    "\n",
    "### Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the execution time\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Query execution time: {execution_time:.2f} seconds\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a158bc53-274b-4243-a979-2a86b668423c",
   "metadata": {},
   "source": [
    "## Step 4: Add Regional Mappings (NUTS Codes to Names)\n",
    "\n",
    "To make the data more readable:\n",
    "1. Load a mapping CSV file from Eurostat containing NUTS codes and corresponding names.\n",
    "2. Extract mappings for:\n",
    "   - **Federal States (NUTS Level 1)**: e.g., \"Baden-Württemberg.\"\n",
    "   - **Districts (NUTS Level 3)**: e.g., \"Stuttgart, Stadtkreis.\"\n",
    "3. Apply these mappings to the query results using Pandas.\n",
    "\n",
    "This step ensures that the visualization contains user-friendly names instead of raw codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49934e44-0ba3-4d75-ae08-6999e1eb4038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add mapping for Bundesland NUTS Code 1 and Landkreis NUTS Code 3 with a mapping CSV from EUROSTAT\n",
    "\n",
    "## Load the prepared CSV file\n",
    "nuts_mapping = pd.read_csv(\"./mappings/nuts_mapping.csv\", delimiter=\",\")\n",
    "\n",
    "## Create separate mappings for federal states and districts\n",
    "federal_state_mapping = (\n",
    "    nuts_mapping[nuts_mapping[\"LEVEL\"] == 1]\n",
    "    .set_index(\"NUTS_ID\")[\"NAME_LATIN\"]\n",
    "    .to_dict()\n",
    ")\n",
    "landkreis_mapping = (\n",
    "    nuts_mapping[nuts_mapping[\"LEVEL\"] == 3]\n",
    "    .set_index(\"NUTS_ID\")[\"NAME_LATIN\"]\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "## Map federal states (NUTS Level 1)\n",
    "df[\"federal_state_name\"] = df[\"nuts_code\"].str[:3].map(federal_state_mapping)\n",
    "\n",
    "## Map Landkreise (NUTS Level 3)\n",
    "df[\"landkreis_name\"] = df[\"nuts_code\"].map(landkreis_mapping)\n",
    "\n",
    "# Display the first few rows of the DataFrame for checking\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8775fc7-c454-46d9-9295-61ad5a3c2f97",
   "metadata": {},
   "source": [
    "## Step 5: Map CPC Subclasses to Titles\n",
    "\n",
    "To enrich the technology field analysis:\n",
    "1. Use the IPC XML scheme provided by WIPO to extract titles for CPC subclasses.\n",
    "2. Parse the XML to extract:\n",
    "   - Subclass symbols (e.g., `B66B`).\n",
    "   - Corresponding titles (e.g., \"Elevators and Lifts\").\n",
    "3. Map these titles to the query results.\n",
    "\n",
    "The result is a dataset with meaningful technology labels, enabling more insightful analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a9057-5dfc-4f89-aa3c-bcef502e4885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start measuring time\n",
    "start = time.time()\n",
    "\n",
    "# File path to the IPC XML\n",
    "filename = \"./mappings/EN_ipc_scheme_20210101.xml\"\n",
    "\n",
    "# Define the namespace and parser\n",
    "ipc_namespace = \"{http://www.wipo.int/classifications/ipc/masterfiles}\"\n",
    "ipcEntry = f\"{ipc_namespace}ipcEntry\"\n",
    "text_body = f\"{ipc_namespace}textBody\"\n",
    "title_part = f\"{ipc_namespace}titlePart\"\n",
    "text = f\"{ipc_namespace}text\"\n",
    "parser = ET.XMLParser(remove_blank_text=True)\n",
    "\n",
    "# Parse the XML file\n",
    "tree = ET.parse(filename, parser=parser)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Initialize dictionary for sub-class mapping\n",
    "sub_class_mapping = {}\n",
    "\n",
    "# Iterate through the XML to extract sub-class information\n",
    "for element in root.iter(ipcEntry):\n",
    "    if element.attrib.get(\"kind\") == \"u\":  # Focus on sub-classes\n",
    "        symbol = element.attrib.get(\"symbol\")  # Extract sub-class symbol\n",
    "\n",
    "        # Locate the title text within the nested structure\n",
    "        text_element = element.find(f\".//{text_body}//{title_part}//{text}\")\n",
    "        title = text_element.text.strip() if text_element is not None else \"No Title\"\n",
    "\n",
    "        sub_class_mapping[symbol] = title\n",
    "\n",
    "# Print a sample of the extracted data\n",
    "# for symbol, title in list(sub_class_mapping.items())[:20]:\n",
    "#    print(f\"{symbol}: {title}\")\n",
    "\n",
    "# Print execution time\n",
    "print(\n",
    "    f\"Extracted {len(sub_class_mapping)} sub-classes in {(time.time() - start) * 1000:.0f} ms.\"\n",
    ")\n",
    "\n",
    "# execute the mapping\n",
    "df[\"cpc_subclass_title\"] = df[\"cpc_subclass\"].map(sub_class_mapping)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f17c3bc-9288-4fbc-9561-af92dd7e9aaf",
   "metadata": {},
   "source": [
    "## Step 6: Refactor the Notebook into a Python Class\n",
    "\n",
    "With all components tested, the process is refactored into a modular Python class called `PatentDataProcessor`.\n",
    "\n",
    "### Key Features:\n",
    "1. **Class-Based Design**:\n",
    "   - Encapsulates the entire process (querying, mapping, visualization).\n",
    "2. **Modular Methods**:\n",
    "   - `load_nuts_mapping`: Load and apply NUTS regional mappings.\n",
    "   - `query_patent_data`: Execute the main SQL query.\n",
    "   - `load_ipc_scheme`: Parse XML for CPC subclass titles.\n",
    "   - `process_data`: Integrate mappings into the dataset.\n",
    "   - `visualize_data`: Launch Pygwalker for visualization.\n",
    "3. **Parameterization**:\n",
    "   - Paths to mapping files and the PATSTAT environment are configurable.\n",
    "\n",
    "This structure makes the code reusable, maintainable, and easy to execute outside the notebook.\n",
    "\n",
    "### Define and execute the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b92beb-702e-432c-8c93-37f4f88ce864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NUTS mapping...\n",
      "Loading IPC scheme...\n",
      "Loaded 646 IPC subclasses in 0.24 seconds.\n",
      "Querying patent data with raw SQL...\n",
      "Query execution time: 40.15 seconds\n",
      "Processing data...\n",
      "Processing time: 18.97 seconds\n",
      "Saving data to disk...\n",
      "Data saved successfully to ./output/patent_data.csv in CSV format in: 11.47 seconds\n",
      "Launching visualization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da85497a8fd344b4ad0a37ffc4ef3d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(HTML(value='\\n<div id=\"ifr-pyg-0006280d1f8e74eau4F5VjCzfrgR0EPU\" style=\"height: auto\">\\n    <hea…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "    window.addEventListener(\"message\", function(event) {\n",
       "        const backgroundMap = {\n",
       "            \"dark\": \"hsl(240 10% 3.9%)\",\n",
       "            \"light\": \"hsl(0 0 100%)\",\n",
       "        };\n",
       "        const colorMap = {\n",
       "            \"dark\": \"hsl(0 0% 98%)\",\n",
       "            \"light\": \"hsl(240 10% 3.9%)\",\n",
       "        };\n",
       "        if (event.data.action === \"changeAppearance\" && event.data.gid === \"0006280d1f8e74eau4F5VjCzfrgR0EPU\") {\n",
       "            var iframe = document.getElementById(\"gwalker-0006280d1f8e74eau4F5VjCzfrgR0EPU\");\n",
       "            iframe.style.background  = backgroundMap[event.data.appearance];\n",
       "            iframe.style.color = colorMap[event.data.appearance];\n",
       "        }\n",
       "    });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import pygwalker as pyg\n",
    "\n",
    "from epo.tipdata.patstat import PatstatClient\n",
    "from epo.tipdata.patstat.database.models import (\n",
    "    TLS201_APPLN,\n",
    "    TLS206_PERSON,\n",
    "    TLS207_PERS_APPLN,\n",
    "    TLS224_APPLN_CPC,\n",
    ")\n",
    "\n",
    "from lxml import etree as ET\n",
    "from sqlalchemy import func, text\n",
    "\n",
    "class PatentDataProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        patstat_env=\"PROD\",\n",
    "        nuts_mapping_path=\"./mappings/nuts_mapping.csv\",\n",
    "        ipc_scheme_path=\"./mappings/EN_ipc_scheme_20210101.xml\",\n",
    "        ipc_namespace=\"{http://www.wipo.int/classifications/ipc/masterfiles}\",\n",
    "    ):\n",
    "        self.patstat = PatstatClient(env=patstat_env)\n",
    "        self.db = self.patstat.orm()\n",
    "        self.nuts_mapping_path = nuts_mapping_path\n",
    "        self.ipc_scheme_path = ipc_scheme_path\n",
    "        self.ipc_namespace = ipc_namespace\n",
    "        self.nuts_mapping = None\n",
    "        self.sub_class_mapping = {}\n",
    "\n",
    "    def load_nuts_mapping(self):\n",
    "        print(\"Loading NUTS mapping...\")\n",
    "        self.nuts_mapping = pd.read_csv(self.nuts_mapping_path, delimiter=\",\")\n",
    "        self.federal_state_mapping = (\n",
    "            self.nuts_mapping[self.nuts_mapping[\"LEVEL\"] == 1]\n",
    "            .set_index(\"NUTS_ID\")[\"NAME_LATIN\"]\n",
    "            .to_dict()\n",
    "        )\n",
    "        self.landkreis_mapping = (\n",
    "            self.nuts_mapping[self.nuts_mapping[\"LEVEL\"] == 3]\n",
    "            .set_index(\"NUTS_ID\")[\"NAME_LATIN\"]\n",
    "            .to_dict()\n",
    "        )\n",
    "        \n",
    "    def query_patent_data(self):\n",
    "        # Query patent data using raw SQL.\n",
    "        print(\"Querying patent data with raw SQL...\")\n",
    "        start = time.time()\n",
    "    \n",
    "        # Define the raw SQL query\n",
    "        sql_query = \"\"\"\n",
    "            SELECT\n",
    "                tls206_person.person_name AS applicant,\n",
    "                tls206_person.nuts AS nuts_code,\n",
    "                tls201_appln.appln_filing_year AS filing_year,\n",
    "                tls224_appln_cpc.cpc_class_symbol AS cpc_subclass,\n",
    "                COUNT(DISTINCT tls201_appln.appln_id) AS appln_count\n",
    "            FROM\n",
    "                tls201_appln\n",
    "            INNER JOIN tls207_pers_appln ON tls201_appln.appln_id = tls207_pers_appln.appln_id\n",
    "            INNER JOIN tls206_person ON tls207_pers_appln.person_id = tls206_person.person_id\n",
    "            INNER JOIN tls224_appln_cpc ON tls201_appln.appln_id = tls224_appln_cpc.appln_id\n",
    "            WHERE\n",
    "                tls206_person.nuts LIKE 'DE%' AND\n",
    "                tls206_person.nuts_level = 3 AND\n",
    "                tls201_appln.appln_filing_year >= EXTRACT(YEAR FROM CURRENT_DATE()) - 10\n",
    "            GROUP BY\n",
    "                tls206_person.person_name,\n",
    "                tls206_person.nuts,\n",
    "                tls201_appln.appln_filing_year,\n",
    "                tls224_appln_cpc.cpc_class_symbol\n",
    "            ORDER BY\n",
    "                tls206_person.nuts, tls201_appln.appln_filing_year, appln_count DESC;\n",
    "        \"\"\"\n",
    "        # Use self.db.bind to access the engine\n",
    "        engine = self.db.bind\n",
    "    \n",
    "        # Execute the raw SQL query\n",
    "        with engine.connect() as connection:\n",
    "            result = connection.execute(text(sql_query))\n",
    "    \n",
    "        # Convert the result to a DataFrame\n",
    "        rows = result.fetchall()\n",
    "        columns = result.keys()\n",
    "        df = pd.DataFrame(rows, columns=columns)\n",
    "    \n",
    "        print(f\"Query execution time: {time.time() - start:.2f} seconds\")\n",
    "        return df\n",
    "        \n",
    "    def load_ipc_scheme(self):\n",
    "        # Load CPC or IPC scheme for CPC subclass titles.\n",
    "        # Note:\n",
    "        # - This method currently uses the IPC scheme.\n",
    "        # - Some CPC-specific subclasses (e.g., Y02 series) may not be covered.\n",
    "        # - To achieve full coverage, switch to the CPC scheme from USPTO/EPO resources.\n",
    "                    \n",
    "        print(\"Loading IPC scheme...\")\n",
    "        start = time.time()\n",
    "    \n",
    "        ipc_namespace = self.ipc_namespace\n",
    "        ipcEntry = f\"{ipc_namespace}ipcEntry\"\n",
    "        text_body = f\"{ipc_namespace}textBody\"\n",
    "        title_part = f\"{ipc_namespace}titlePart\"\n",
    "        text = f\"{ipc_namespace}text\"\n",
    "    \n",
    "        parser = ET.XMLParser(remove_blank_text=True)\n",
    "        tree = ET.parse(self.ipc_scheme_path, parser=parser)\n",
    "        root = tree.getroot()\n",
    "    \n",
    "        for element in root.iter(ipcEntry):\n",
    "            if element.attrib.get(\"kind\") == \"u\":  # Subclass kind is \"u\"\n",
    "                symbol = element.attrib.get(\"symbol\")\n",
    "                text_element = element.find(f\".//{text_body}//{title_part}//{text}\")\n",
    "                title = text_element.text.strip() if text_element is not None else \"No Title\"\n",
    "                self.sub_class_mapping[symbol] = title\n",
    "    \n",
    "        # Log a sample of loaded subclass titles\n",
    "        # print(f\"Sample CPC Subclass Titles: {list(self.sub_class_mapping.items())[:5]}\")\n",
    "        \n",
    "        print(f\"Loaded {len(self.sub_class_mapping)} IPC subclasses in {(time.time() - start):.2f} seconds.\")\n",
    "\n",
    "    def process_data(self, df):\n",
    "        print(\"Processing data...\")\n",
    "        start = time.time()\n",
    "    \n",
    "        # Add federal state codes and names\n",
    "        df[\"federal_state_code\"] = df[\"nuts_code\"].str[:3]\n",
    "        df[\"federal_state_name\"] = df[\"federal_state_code\"].map(self.federal_state_mapping)\n",
    "        df[\"landkreis_name\"] = df[\"nuts_code\"].map(self.landkreis_mapping)\n",
    "    \n",
    "        # Normalize CPC subclass\n",
    "        if \"cpc_subclass\" in df.columns:\n",
    "            df[\"normalized_cpc_subclass\"] = df[\"cpc_subclass\"].str[:4]\n",
    "    \n",
    "            # Map CPC titles\n",
    "            df[\"cpc_subclass_title\"] = df[\"normalized_cpc_subclass\"].map(self.sub_class_mapping)\n",
    "    \n",
    "            # Combine subclass and title into one column\n",
    "            df[\"cpc_combined\"] = df.apply(\n",
    "                lambda row: f\"{row['normalized_cpc_subclass']} - {row['cpc_subclass_title']}\"\n",
    "                if pd.notna(row['cpc_subclass_title']) else row['normalized_cpc_subclass'],\n",
    "                axis=1\n",
    "            )\n",
    "        else:\n",
    "            print(\"Warning: 'cpc_subclass' column is missing. CPC subclass titles will not be added.\")\n",
    "    \n",
    "        print(f\"Processing time: {time.time() - start:.2f} seconds\")\n",
    "        return df\n",
    "\n",
    "    def save_data(self, df, file_path, file_format=\"csv\"):\n",
    "        \n",
    "        print(\"Saving data to disk...\")\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        supported_formats = [\"csv\", \"excel\", \"json\"]\n",
    "        \n",
    "        if file_format not in supported_formats:\n",
    "            raise ValueError(f\"Unsupported file format: {file_format}. Supported formats are {supported_formats}.\")\n",
    "\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        \n",
    "        if file_format == \"csv\":\n",
    "            df.to_csv(file_path, index=False)\n",
    "        elif file_format == \"excel\":\n",
    "            df.to_excel(file_path, index=False, engine=\"openpyxl\")\n",
    "        elif file_format == \"json\":\n",
    "            df.to_json(file_path, orient=\"records\")\n",
    "            \n",
    "        print(f\"Data saved successfully to {file_path} in {file_format.upper()} format in: {time.time() - start:.2f} seconds\")\n",
    "    \n",
    "    def visualize_data(self, df):\n",
    "        \n",
    "        print(\"Launching visualization...\")\n",
    "\n",
    "        df\n",
    "        \n",
    "        pyg.walk(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Instantiate and execute the workflow\n",
    "    processor = PatentDataProcessor(patstat_env=\"PROD\")\n",
    "    \n",
    "    # Step 1: Load mappings\n",
    "    processor.load_nuts_mapping()\n",
    "    processor.load_ipc_scheme()\n",
    "    \n",
    "    # Step 2: Query data\n",
    "    patent_data = processor.query_patent_data()\n",
    "    \n",
    "    # Step 3: Process data\n",
    "    processed_data = processor.process_data(patent_data)\n",
    "    \n",
    "    # Step 4: Save the processed data\n",
    "    processor.save_data(processed_data, file_path=\"./output/patent_data.csv\", file_format=\"csv\")\n",
    "    \n",
    "    # Step 5: Visualize the data (optional)\n",
    "    processor.visualize_data(processed_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f114179-081f-47ed-9092-ce12e448b705",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Additional Documentation: Analyzing the SQL Query in `PatentDataProcessor`\n",
    "\n",
    "This guide breaks down the SQL query used in the `query_patent_data` method of the `PatentDataProcessor` class. The query retrieves and joins data from PATSTAT tables to analyze patent applicants, their geographical locations, and associated technologies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9b6a1-1bf3-425c-a6e8-855193c91092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec466253-7b6c-49ae-a433-cb4edd9c4caf",
   "metadata": {},
   "source": [
    "```SQL\n",
    "            SELECT\n",
    "                tls206_person.person_name AS applicant,\n",
    "                tls206_person.nuts AS nuts_code,\n",
    "                tls201_appln.appln_filing_year AS filing_year,\n",
    "                tls201_appln.granted,\n",
    "                tls224_appln_cpc.cpc_class_symbol AS technology_field,\n",
    "                COUNT(tls201_appln.appln_id) AS appln_count\n",
    "            FROM\n",
    "                tls201_appln\n",
    "            INNER JOIN tls207_pers_appln ON tls201_appln.appln_id = tls207_pers_appln.appln_id\n",
    "            INNER JOIN tls206_person ON tls207_pers_appln.person_id = tls206_person.person_id\n",
    "            INNER JOIN tls224_appln_cpc ON tls201_appln.appln_id = tls224_appln_cpc.appln_id\n",
    "            WHERE\n",
    "                tls206_person.nuts LIKE 'DE%' AND\n",
    "                tls206_person.nuts_level = 3\n",
    "                tls201_appln.appln_filing_year >= EXTRACT(YEAR FROM CURRENT_DATE) - 20\n",
    "            GROUP BY\n",
    "                tls201_appln.appln_filing_year,\n",
    "                tls206_person.nuts,\n",
    "                tls224_appln_cpc.cpc_class_symbol,\n",
    "                tls206_person.person_name,\n",
    "                tls201_appln.granted\n",
    "            ORDER BY\n",
    "                tls206_person.nuts;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4381a27-c215-41f6-a414-811db8d354a2",
   "metadata": {},
   "source": [
    "### **Tables and Columns in Use**\n",
    "\n",
    "The query utilizes the following PATSTAT tables:\n",
    "\n",
    "#### 1. **`TLS206_PERSON` (Person Table)**\n",
    "- Contains information about applicants, inventors, and their addresses.\n",
    "- **Columns used:**\n",
    "  - `person_name`: The name of the applicant or inventor.\n",
    "  - `nuts`: The NUTS code (geographical region) for the person.\n",
    "  - `nuts_level`: The granularity of the NUTS code (e.g., level 3 corresponds to districts or Landkreise).\n",
    "\n",
    "#### 2. **`TLS207_PERS_APPLN` (Link Table: Person-Application)**\n",
    "- Links persons (from `TLS206_PERSON`) to patent applications.\n",
    "- **Columns used:**\n",
    "  - `person_id`: Connects to the `TLS206_PERSON` table.\n",
    "  - `appln_id`: Connects to the `TLS201_APPLN` table.\n",
    "\n",
    "#### 3. **`TLS201_APPLN` (Application Table)**\n",
    "- Contains metadata about patent applications.\n",
    "- **Columns used:**\n",
    "  - `appln_id`: The unique identifier for an application.\n",
    "  - `appln_filing_year`: The year the application was filed.\n",
    "  - `granted`: Indicates if the patent was granted (e.g., `'Y'` for yes).\n",
    "\n",
    "#### 4. **`TLS224_APPLN_CPC` (Classification Table)**\n",
    "- Contains CPC (Cooperative Patent Classification) codes for applications.\n",
    "- **Columns used:**\n",
    "  - `appln_id`: Connects to `TLS201_APPLN`.\n",
    "  - `cpc_class_symbol`: The CPC classification code for the application.\n",
    "\n",
    "---\n",
    "\n",
    "### **What the Query Does**\n",
    "\n",
    "#### **Selected Columns**\n",
    "- `TLS206_PERSON.person_name` → Applicant name.\n",
    "- `TLS206_PERSON.nuts` → Full NUTS code for geographical information.\n",
    "- `TLS224_APPLN_CPC.cpc_class_symbol` → The CPC technology field for the application.\n",
    "- `TLS201_APPLN.appln_filing_year` → The year the patent was filed.\n",
    "- `TLS201_APPLN.granted` → Indicates whether the patent was granted.\n",
    "- `func.count(TLS201_APPLN.appln_id)` → Counts the number of applications grouped by the selected fields.\n",
    "\n",
    "#### **Joins**\n",
    "- Links the `TLS206_PERSON` table to the application data:\n",
    "  - `TLS206_PERSON` → `TLS207_PERS_APPLN` → `TLS201_APPLN` → `TLS224_APPLN_CPC`.\n",
    "- This links applicants, their geographical information, and the CPC classifications.\n",
    "\n",
    "#### **Filters**\n",
    "- `TLS206_PERSON.nuts.startswith(\"DE\")` → Restricts results to Germany.\n",
    "- `TLS206_PERSON.nuts_level == 3` → Focuses on NUTS Level 3 regions (districts).\n",
    "\n",
    "#### **Grouping**\n",
    "The query groups data by:\n",
    "- Filing year (`appln_filing_year`).\n",
    "- Full NUTS code and federal state code (`nuts`, `SUBSTR(nuts, 1, 3)`).\n",
    "- CPC class and subclass (`cpc_class_symbol`, `SUBSTR(cpc_class_symbol, 1, 4)`).\n",
    "- Applicant name (`person_name`).\n",
    "- Grant status (`granted`).\n",
    "\n",
    "#### **Ordering**\n",
    "- Orders results by the NUTS code for consistent geographical sorting.\n",
    "\n",
    "---\n",
    "\n",
    "### **Expected Output**\n",
    "\n",
    "The query generates a dataset with the following columns:\n",
    "1. **`applicant`**: Applicant name.\n",
    "2. **`nuts_code`**: NUTS Level 3 region.\n",
    "3. **`federal_state_code`**: Federal state derived from the NUTS code.\n",
    "4. **`technology_field`**: CPC class symbol (e.g., `B66B` for \"Elevators and Lifts\").\n",
    "5. **`cpc_subclass`**: First four characters of the CPC class symbol for further granularity.\n",
    "6. **`filing_year`**: Filing year of the application.\n",
    "7. **`granted`**: Grant status (`Y` or `N`).\n",
    "8. **`appln_count`**: Count of applications for the grouped criteria.\n",
    "\n",
    "---\n",
    "\n",
    "### **Purpose of the Query**\n",
    "\n",
    "#### **1. Geographical Analysis**\n",
    "- Understand patent activity across districts (NUTS Level 3) and federal states (NUTS Level 1).\n",
    "\n",
    "#### **2. Technological Insights**\n",
    "- Identify technology trends by CPC classifications.\n",
    "\n",
    "#### **3. Applicant Activity**\n",
    "- Recognize active applicants in specific regions and technology fields.\n",
    "\n",
    "#### **4. Visualization**\n",
    "- Prepares data for creating maps and interactive charts using tools like **Pygwalker** or **Datawrapper**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
